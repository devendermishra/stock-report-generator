# GPU Requirements for Stock Report Generator
# This file contains GPU-specific dependencies for AI model acceleration
# 
# Prerequisites:
# - NVIDIA GPU with CUDA Compute Capability 6.0 or higher
# - CUDA Toolkit 11.8 or 12.0
# - cuDNN 8.6 or higher
# - NVIDIA drivers 520.61.05 or higher
# - nvidia-docker2 (for Docker GPU support)

# Core dependencies (from requirements.txt)
python-dotenv>=1.0.0
requests>=2.31.0

# Data processing
pandas>=2.2.0
numpy>=1.26.0

# LangGraph and LangChain orchestration
langgraph>=0.0.62
langchain>=0.1.0
langchain-openai>=0.0.5

# OpenAI API
openai>=1.12.0

# Financial data
yfinance>=0.2.28

# PDF processing and generation
PyPDF2>=3.0.1
PyMuPDF>=1.23.8
reportlab>=4.0.0
markdown>=3.5.0

# Web search
ddgs>=8.0.0

# HTML/XML parsing (used by web search and PDF tools)
beautifulsoup4>=4.12.2
lxml>=5.2.1

# Async HTTP support
aiohttp>=3.9.1

# GPU-Specific Dependencies
# PyTorch GPU Support (for local model inference if needed)
torch>=2.0.0  # PyTorch with CUDA support (requires CUDA 11.8+)
torchvision>=0.15.0  # Computer vision utilities
torchaudio>=2.0.0  # Audio processing utilities

# GPU Monitoring and Management
nvidia-ml-py>=11.0.0  # GPU monitoring and management
pynvml>=11.0.0  # GPU memory monitoring
gpustat>=1.1.0  # GPU status monitoring CLI tool

# Performance Optimization (Optional)
accelerate>=0.20.0  # Distributed training and inference acceleration
numba>=0.57.0  # JIT compilation with GPU support

# Installation Notes:
# 1. Install CUDA Toolkit first: https://developer.nvidia.com/cuda-downloads
# 2. Install cuDNN: https://developer.nvidia.com/cudnn
# 3. Install nvidia-docker2 for Docker GPU support: sudo apt-get install nvidia-docker2
# 4. Install requirements: pip install -r requirements-gpu.txt
# 5. Verify GPU support: python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
#
# Note: This project primarily uses OpenAI API (cloud-based). GPU acceleration is useful
# if you plan to run local LLM models or perform GPU-accelerated data processing.
